{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "910512b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score, StratifiedKFold, cross_validate\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe49378a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataframe(y_pred, num):\n",
    "    df = pd.DataFrame(y_pred, columns = ['Predicted'])\n",
    "    read_file = pd.read_csv('test_II.csv')\n",
    "    df.insert(0, 'Id', read_file['x'], True)\n",
    "    df.to_csv(f'submission{num}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c942f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assay ID                      int64\n",
      "MaxEStateIndex              float64\n",
      "MinEStateIndex              float64\n",
      "MaxAbsEStateIndex           float64\n",
      "MinAbsEStateIndex           float64\n",
      "qed                         float64\n",
      "MolWt                       float64\n",
      "HeavyAtomMolWt              float64\n",
      "ExactMolWt                  float64\n",
      "NumValenceElectrons           int64\n",
      "NumRadicalElectrons           int64\n",
      "MaxPartialCharge            float64\n",
      "MinPartialCharge            float64\n",
      "MaxAbsPartialCharge         float64\n",
      "MinAbsPartialCharge         float64\n",
      "FpDensityMorgan1            float64\n",
      "FpDensityMorgan2            float64\n",
      "FpDensityMorgan3            float64\n",
      "BCUT2D_MWHI                 float64\n",
      "BCUT2D_MWLOW                float64\n",
      "BCUT2D_CHGHI                float64\n",
      "BCUT2D_CHGLO                float64\n",
      "BCUT2D_LOGPHI               float64\n",
      "BCUT2D_LOGPLOW              float64\n",
      "BCUT2D_MRHI                 float64\n",
      "BCUT2D_MRLOW                float64\n",
      "BalabanJ                    float64\n",
      "BertzCT                     float64\n",
      "Chi0                        float64\n",
      "Chi0n                       float64\n",
      "Chi0v                       float64\n",
      "Chi1                        float64\n",
      "Chi1n                       float64\n",
      "Chi1v                       float64\n",
      "Chi2n                       float64\n",
      "Chi2v                       float64\n",
      "Chi3n                       float64\n",
      "Chi3v                       float64\n",
      "Chi4n                       float64\n",
      "Chi4v                       float64\n",
      "HallKierAlpha               float64\n",
      "Ipc                         float64\n",
      "Kappa1                      float64\n",
      "Kappa2                      float64\n",
      "Kappa3                      float64\n",
      "LabuteASA                   float64\n",
      "PEOE_VSA1                   float64\n",
      "PEOE_VSA10                  float64\n",
      "PEOE_VSA11                  float64\n",
      "PEOE_VSA12                  float64\n",
      "PEOE_VSA13                  float64\n",
      "PEOE_VSA14                  float64\n",
      "PEOE_VSA2                   float64\n",
      "PEOE_VSA3                   float64\n",
      "PEOE_VSA4                   float64\n",
      "PEOE_VSA5                   float64\n",
      "PEOE_VSA6                   float64\n",
      "PEOE_VSA7                   float64\n",
      "PEOE_VSA8                   float64\n",
      "PEOE_VSA9                   float64\n",
      "SMR_VSA1                    float64\n",
      "SMR_VSA10                   float64\n",
      "SMR_VSA2                    float64\n",
      "SMR_VSA3                    float64\n",
      "SMR_VSA4                    float64\n",
      "SMR_VSA5                    float64\n",
      "SMR_VSA6                    float64\n",
      "SMR_VSA7                    float64\n",
      "SMR_VSA8                    float64\n",
      "SMR_VSA9                    float64\n",
      "SlogP_VSA1                  float64\n",
      "SlogP_VSA10                 float64\n",
      "SlogP_VSA11                 float64\n",
      "SlogP_VSA12                 float64\n",
      "SlogP_VSA2                  float64\n",
      "SlogP_VSA3                  float64\n",
      "SlogP_VSA4                  float64\n",
      "SlogP_VSA5                  float64\n",
      "SlogP_VSA6                  float64\n",
      "SlogP_VSA7                  float64\n",
      "SlogP_VSA8                  float64\n",
      "SlogP_VSA9                  float64\n",
      "TPSA                        float64\n",
      "EState_VSA1                 float64\n",
      "EState_VSA10                float64\n",
      "EState_VSA11                float64\n",
      "EState_VSA2                 float64\n",
      "EState_VSA3                 float64\n",
      "EState_VSA4                 float64\n",
      "EState_VSA5                 float64\n",
      "EState_VSA6                 float64\n",
      "EState_VSA7                 float64\n",
      "EState_VSA8                 float64\n",
      "EState_VSA9                 float64\n",
      "VSA_EState1                 float64\n",
      "VSA_EState10                float64\n",
      "VSA_EState2                 float64\n",
      "VSA_EState3                 float64\n",
      "VSA_EState4                 float64\n",
      "VSA_EState5                 float64\n",
      "VSA_EState6                 float64\n",
      "VSA_EState7                 float64\n",
      "VSA_EState8                 float64\n",
      "VSA_EState9                 float64\n",
      "FractionCSP3                float64\n",
      "HeavyAtomCount                int64\n",
      "NHOHCount                     int64\n",
      "NOCount                       int64\n",
      "NumAliphaticCarbocycles       int64\n",
      "NumAliphaticHeterocycles      int64\n",
      "NumAliphaticRings             int64\n",
      "NumAromaticCarbocycles        int64\n",
      "NumAromaticHeterocycles       int64\n",
      "NumAromaticRings              int64\n",
      "NumHAcceptors                 int64\n",
      "NumHDonors                    int64\n",
      "NumHeteroatoms                int64\n",
      "NumRotatableBonds             int64\n",
      "NumSaturatedCarbocycles       int64\n",
      "NumSaturatedHeterocycles      int64\n",
      "NumSaturatedRings             int64\n",
      "RingCount                     int64\n",
      "MolLogP                     float64\n",
      "MolMR                       float64\n",
      "fr_Al_COO                     int64\n",
      "fr_Al_OH                      int64\n",
      "fr_Al_OH_noTert               int64\n",
      "fr_ArN                        int64\n",
      "fr_Ar_COO                     int64\n",
      "fr_Ar_N                       int64\n",
      "fr_Ar_NH                      int64\n",
      "fr_Ar_OH                      int64\n",
      "fr_COO                        int64\n",
      "fr_COO2                       int64\n",
      "fr_C_O                        int64\n",
      "fr_C_O_noCOO                  int64\n",
      "fr_C_S                        int64\n",
      "fr_HOCCN                      int64\n",
      "fr_Imine                      int64\n",
      "fr_NH0                        int64\n",
      "fr_NH1                        int64\n",
      "fr_NH2                        int64\n",
      "fr_N_O                        int64\n",
      "fr_Ndealkylation1             int64\n",
      "fr_Ndealkylation2             int64\n",
      "fr_Nhpyrrole                  int64\n",
      "fr_SH                         int64\n",
      "fr_aldehyde                   int64\n",
      "fr_alkyl_carbamate            int64\n",
      "fr_alkyl_halide               int64\n",
      "fr_allylic_oxid               int64\n",
      "fr_amide                      int64\n",
      "fr_amidine                    int64\n",
      "fr_aniline                    int64\n",
      "fr_aryl_methyl                int64\n",
      "fr_azide                      int64\n",
      "fr_azo                        int64\n",
      "fr_barbitur                   int64\n",
      "fr_benzene                    int64\n",
      "fr_benzodiazepine             int64\n",
      "fr_bicyclic                   int64\n",
      "fr_diazo                      int64\n",
      "fr_dihydropyridine            int64\n",
      "fr_epoxide                    int64\n",
      "fr_ester                      int64\n",
      "fr_ether                      int64\n",
      "fr_furan                      int64\n",
      "fr_guanido                    int64\n",
      "fr_halogen                    int64\n",
      "fr_hdrzine                    int64\n",
      "fr_hdrzone                    int64\n",
      "fr_imidazole                  int64\n",
      "fr_imide                      int64\n",
      "fr_isocyan                    int64\n",
      "fr_isothiocyan                int64\n",
      "fr_ketone                     int64\n",
      "fr_ketone_Topliss             int64\n",
      "fr_lactam                     int64\n",
      "fr_lactone                    int64\n",
      "fr_methoxy                    int64\n",
      "fr_morpholine                 int64\n",
      "fr_nitrile                    int64\n",
      "fr_nitro                      int64\n",
      "fr_nitro_arom                 int64\n",
      "fr_nitro_arom_nonortho        int64\n",
      "fr_nitroso                    int64\n",
      "fr_oxazole                    int64\n",
      "fr_oxime                      int64\n",
      "fr_para_hydroxylation         int64\n",
      "fr_phenol                     int64\n",
      "fr_phenol_noOrthoHbond        int64\n",
      "fr_phos_acid                  int64\n",
      "fr_phos_ester                 int64\n",
      "fr_piperdine                  int64\n",
      "fr_piperzine                  int64\n",
      "fr_priamide                   int64\n",
      "fr_prisulfonamd               int64\n",
      "fr_pyridine                   int64\n",
      "fr_quatN                      int64\n",
      "fr_sulfide                    int64\n",
      "fr_sulfonamd                  int64\n",
      "fr_sulfone                    int64\n",
      "fr_term_acetylene             int64\n",
      "fr_tetrazole                  int64\n",
      "fr_thiazole                   int64\n",
      "fr_thiocyan                   int64\n",
      "fr_thiophene                  int64\n",
      "fr_unbrch_alkane              int64\n",
      "fr_urea                       int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "train_dataset = pd.read_csv('feature_descriptors.csv')\n",
    "train_dataset.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "train_dataset.fillna(0,inplace=True)\n",
    "# print(dataset.isnull().sum())\n",
    "\n",
    "# print(train_dataset.shape)\n",
    "\n",
    "train_y = train_dataset['Expected']\n",
    "\n",
    "train_x = train_dataset.drop(['Expected'], axis = 1)\n",
    "print(train_x.dtypes)\n",
    "# test data\n",
    "\n",
    "test_dataset = pd.read_csv('test_feature_desc.csv')\n",
    "test_dataset.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "\n",
    "test_dataset.fillna(0, inplace=True)\n",
    "# print(test_dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a93c6808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm linear\n",
    "def run_svm():\n",
    "    svm_classifier = SVC(kernel = 'linear')\n",
    "    model=svm_classifier.fit(train_x, train_y)\n",
    "    pred_y = model.predict(test_dataset)\n",
    "    generate_dataframe(pred_y, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12b2c58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#naive bayes classifier\n",
    "def run_naive():\n",
    "    naive_bayes_classifier = GaussianNB()  \n",
    "    model=naive_bayes_classifier.fit(train_x, train_y)\n",
    "    nb_pred_y = model.predict(test_dataset)\n",
    "    generate_dataframe(nb_pred_y, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bc6a0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm poly \n",
    "def run_svm_poly():\n",
    "    svm_poly = SVC(kernel = 'poly')\n",
    "    model=svm_poly.fit(train_x, train_y)\n",
    "    svm_poly_pred_y = model.predict(test_dataset)\n",
    "    generate_dataframe(svm_poly_pred_y, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bf13c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  svm rbf \n",
    "def run_svm_rbf():\n",
    "    svm_r = SVC(kernel = 'rbf', gamma=0.000001, C=1)\n",
    "    model=svm_r.fit(train_x, train_y)\n",
    "    svm_r_pred_y = model.predict(test_dataset)\n",
    "    generate_dataframe(svm_r_pred_y, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e73d365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn = 7\n",
    "def run_knn_7():\n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors=7)\n",
    "    model=knn_classifier.fit(train_x, train_y)\n",
    "    pred_y = model.predict(test_dataset)\n",
    "    generate_dataframe(pred_y, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3697ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#knn = 70 and fill null values with mean\n",
    "def run_knn_70():\n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors=70)\n",
    "    model=knn_classifier.fit(train_x, train_y)\n",
    "    pred_y = model.predict(test_dataset)\n",
    "    generate_dataframe(pred_y, 6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fc0dc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#knn = 29 and fill null values with mean\n",
    "def run_knn_29():\n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors=29)\n",
    "    model = knn_classifier.fit(train_x, train_y)\n",
    "    pred_y = model.predict(test_dataset)\n",
    "    generate_dataframe(pred_y, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa67f8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_knn_17():\n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors=17)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    n_scores = cross_val_score(knn_classifier, train_x, train_y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    print('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))\n",
    "\n",
    "    model = knn_classifier.fit(train_x, train_y)\n",
    "    pred_y = model.predict(test_dataset)\n",
    "    generate_dataframe(pred_y, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c67744c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra tree classifier\n",
    "def extra_tree():\n",
    "    extra_tree_classifier = ExtraTreesClassifier()\n",
    "    \n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    n_scores = cross_val_score(extra_tree_classifier, train_x, train_y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    print('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))\n",
    "    \n",
    "    model = extra_tree_classifier.fit(train_x, train_y)\n",
    "    pred_y = model.predict(test_dataset)\n",
    "    generate_dataframe(pred_y, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3db17708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient boosting - high acc\n",
    "def gradient_boosting():\n",
    "    gb = GradientBoostingClassifier(learning_rate=0.5)\n",
    "    \n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    n_scores = cross_val_score(gb, train_x, train_y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    print('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))\n",
    "    \n",
    "    model = gb.fit(train_x, train_y)\n",
    "    print(model.feature_importances_)\n",
    "\n",
    "    pred_y = model.predict(test_dataset)\n",
    "    generate_dataframe(pred_y, 10)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80dd863f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extra_tree_200():\n",
    "    extra_tree_classifier = ExtraTreesClassifier(n_estimators=200)\n",
    "    \n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    n_scores = cross_val_score(extra_tree_classifier, train_x, train_y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    print('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))\n",
    "    \n",
    "    model = extra_tree_classifier.fit(train_x, train_y)\n",
    "    pred_y = model.predict(test_dataset)\n",
    "    generate_dataframe(pred_y, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0e511b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost12():\n",
    "    xgb = XGBClassifier()\n",
    "    le = LabelEncoder()\n",
    "    y_train = le.fit_transform(train_y)\n",
    "    \n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=4)\n",
    "    n_scores = cross_validate(xgb, train_x, y_train, cv=kfold, scoring='f1', n_jobs=6)\n",
    "    print(np.mean(n_scores['test_score']))\n",
    "    \n",
    "    model = xgb.fit(train_x, y_train)  \n",
    "    pred_y = model.predict(test_dataset)\n",
    "    generate_dataframe(pred_y, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ef39c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost13():\n",
    "    xgb = XGBClassifier()\n",
    "    le = LabelEncoder()\n",
    "    y_train = le.fit_transform(train_y)\n",
    "    \n",
    "    \n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=4)\n",
    "    n_scores = cross_validate(xgb, train_x, y_train, cv=kfold, scoring='f1', n_jobs=6)\n",
    "    print(np.mean(n_scores['test_score']))\n",
    "    \n",
    "    model = xgb.fit(train_x, y_train)\n",
    "    \n",
    "    \n",
    "    # y_train = le.inverse_transform(y_train)\n",
    "    pred_y = model.predict(test_dataset)\n",
    "    y_new = le.inverse_transform(pred_y)\n",
    "    generate_dataframe(y_new, 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dbe2c0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost14():\n",
    "    xgb = XGBClassifier(learning_rate=0.1, max_depth=10, n_estimators=1000, objective='binary:logistic', nthread=4, seed=42)\n",
    "    le = LabelEncoder()\n",
    "    y_train = le.fit_transform(train_y)\n",
    "    \n",
    "    estimator = XGBClassifier(objective='binary:logistic', nthread=4, seed=42)\n",
    "\n",
    "    parameters = {'max_depth': [8, 10], 'n_estimators': [1000, 1200], 'learning_rate': [0.1,0.2]}\n",
    "\n",
    "    grid_search = GridSearchCV(estimator=estimator, param_grid=parameters, scoring='f1', n_jobs=6, cv=5, verbose=True)\n",
    "\n",
    "    grid_search.fit(train_x, y_train)\n",
    "\n",
    "    print(grid_search.best_params_, grid_search.best_score_)\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, random_state=1, shuffle=True)\n",
    "    n_scores = cross_validate(xgb, train_x, y_train, scoring='f1', cv=cv, n_jobs=-1)\n",
    "    print(np.mean(n_scores['test_score']))\n",
    "\n",
    "\n",
    "\n",
    "    model = xgb.fit(train_x, y_train)\n",
    "    pred_y = model.predict(test_dataset)\n",
    "    y_new = le.inverse_transform(pred_y)\n",
    "    generate_dataframe(y_new, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "847097f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost15():\n",
    "    xgb = XGBClassifier(learning_rate=0.1, max_depth=8, n_estimators=1200, objective='binary:logistic', nthread=4, seed=42)\n",
    "    le = LabelEncoder()\n",
    "    y_train = le.fit_transform(train_y)\n",
    "    \n",
    "    estimator = XGBClassifier(objective='binary:logistic', nthread=4, seed=42)\n",
    "\n",
    "    parameters = {'max_depth': [8, 10], 'n_estimators': [1000, 1200], 'learning_rate': [0.1,0.2]}\n",
    "\n",
    "    grid_search = GridSearchCV(estimator=estimator, param_grid=parameters, scoring='f1', n_jobs=6, cv=5, verbose=True)\n",
    "\n",
    "    grid_search.fit(train_x, y_train)cr\n",
    "\n",
    "    print(grid_search.best_params_, grid_search.best_score_)\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, random_state=1, shuffle=True)\n",
    "    n_scores = cross_validate(xgb, train_x, y_train, scoring='f1', cv=cv, n_jobs=-1)\n",
    "    print(np.mean(n_scores['test_score']))\n",
    "\n",
    "    model = xgb.fit(train_x, y_train)\n",
    "    pred_y = model.predict(test_dataset)\n",
    "    y_new = le.inverse_transform(pred_y)\n",
    "    generate_dataframe(y_new, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bde1a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost16():\n",
    "    xgb = XGBClassifier()\n",
    "    le = LabelEncoder()\n",
    "    y_train = le.fit_transform(train_y)\n",
    "    \n",
    "    estimator = XGBClassifier(objective='binary:logistic', nthread=4, seed=42)\n",
    "\n",
    "    parameters = {'n_estimators': [1500, 1200], 'learning_rate': [0.1,0.2], 'max_depth':[8,10]}\n",
    "\n",
    "    grid_search = GridSearchCV(estimator=estimator, param_grid=parameters, scoring='f1', n_jobs=6, cv=5, verbose=True)\n",
    "\n",
    "    grid_search.fit(train_x, y_train)\n",
    "\n",
    "    print(grid_search.best_params_, grid_search.best_score_)\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, random_state=1, shuffle=True)\n",
    "    n_scores = cross_validate(xgb, train_x, y_train, scoring='f1', cv=cv, n_jobs=-1)\n",
    "    print(np.mean(n_scores['test_score']))\n",
    "\n",
    "    model = xgb.fit(train_x, y_train)\n",
    "    pred_y = model.predict(test_dataset)\n",
    "    y_new = le.inverse_transform(pred_y)\n",
    "    generate_dataframe(y_new, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8f637523",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stacking17():\n",
    "    le = LabelEncoder()\n",
    "    y_train = le.fit_transform(train_y) # 0, 1\n",
    "    level_0_clf = dict()\n",
    "    level_0_clf['random_forest'] = RandomForestClassifier(n_estimators=500, random_state=3)\n",
    "    level_0_clf['extra_tree'] = ExtraTreesClassifier(n_estimators=200)\n",
    "    level_0_clf['gradient_boosting'] = GradientBoostingClassifier(learning_rate=0.5)\n",
    "#     level_0_clf['xgboost'] = XGBClassifier(learning_rate=0.1, max_depth=8, n_estimators=1200, objective='binary:logistic', nthread=4, seed=42)\n",
    "    level_1_clf = XGBClassifier()\n",
    "\n",
    "    \n",
    "    stacking_model = StackingClassifier(estimators=list(level_0_clf.items()), final_estimator=level_1_clf)\n",
    "                                        \n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=4)\n",
    "    n_scores = cross_validate(stacking_model, train_x, y_train, cv=kfold, scoring='f1', n_jobs=6)\n",
    "    print(np.mean(n_scores['test_score']))\n",
    "\n",
    "    model = stacking_model.fit(train_x, y_train)\n",
    "    pred_y = model.predict(test_dataset)\n",
    "    y_new = le.inverse_transform(pred_y)\n",
    "    generate_dataframe(y_new, 17)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "105ffca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stacking18():\n",
    "    le = LabelEncoder()\n",
    "    y_train = le.fit_transform(train_y) # 0, 1\n",
    "    level_0_clf = dict()\n",
    "#     level_0_clf['random_forest'] = RandomForestClassifier(n_estimators=100, random_state=3)\n",
    "    level_0_clf['extra_tree'] = ExtraTreesClassifier(n_estimators=200)\n",
    "    level_0_clf['gradient_boosting'] = GradientBoostingClassifier(learning_rate=0.5)\n",
    "    level_0_clf['xgboost'] = XGBClassifier(learning_rate=0.1, max_depth=8, n_estimators=1200, objective='binary:logistic', nthread=4, seed=42)\n",
    "    level_1_clf = XGBClassifier()\n",
    "\n",
    "    \n",
    "    stacking_model = StackingClassifier(estimators=list(level_0_clf.items()), final_estimator=level_1_clf)\n",
    "                                        \n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=4)\n",
    "    n_scores = cross_validate(stacking_model, train_x, y_train, cv=kfold, scoring='f1', n_jobs=6)\n",
    "    print(np.mean(n_scores['test_score']))\n",
    "    \n",
    "    model = stacking_model.fit(train_x, y_train)\n",
    "    pred_y = model.predict(test_dataset)\n",
    "    y_new = le.inverse_transform(pred_y)\n",
    "    generate_dataframe(y_new, 18)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a86ac2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stacking19():\n",
    "    le = LabelEncoder()\n",
    "    y_train = le.fit_transform(train_y) # 0, 1\n",
    "    level_0_clf = dict()\n",
    "#     level_0_clf['random_forest'] = RandomForestClassifier(n_estimators=100, random_state=3)\n",
    "    level_0_clf['extra_tree'] = ExtraTreesClassifier(n_estimators=200)\n",
    "    level_0_clf['gradient_boosting'] = GradientBoostingClassifier(learning_rate=0.5)\n",
    "    level_0_clf['xgboost'] = XGBClassifier(tree_method='hist', learning_rate=0.1, max_depth=8, n_estimators=1200, objective='binary:logistic', nthread=4, seed=42)\n",
    "    level_1_clf = XGBClassifier()\n",
    "\n",
    "    \n",
    "    stacking_model = StackingClassifier(estimators=list(level_0_clf.items()), final_estimator=level_1_clf)\n",
    "                                        \n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=4)\n",
    "    n_scores = cross_validate(stacking_model, train_x, y_train, cv=kfold, scoring='f1', n_jobs=6)\n",
    "    print(np.mean(n_scores['test_score']))\n",
    "    \n",
    "    model = stacking_model.fit(train_x, y_train)\n",
    "    pred_y = model.predict(test_dataset)\n",
    "    y_new = le.inverse_transform(pred_y)\n",
    "    generate_dataframe(y_new, 19)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c5ef1ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb25():\n",
    "    le = LabelEncoder()\n",
    "    y_train = le.fit_transform(train_y)\n",
    "    xgb = XGBClassifier(\n",
    "    tree_method='hist', max_bin=255, n_estimators=600, learning_rate=0.1, objective='binary:logistic', gamma=0.65, reg_alpha=0.9, reg_lambda=0.89, subsample=0.99,\n",
    "    colsample_bytree = 0.99, max_depth=10, colsample_bylevel=0.99\n",
    ")\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=4)\n",
    "    n_scores = cross_validate(xgb, train_x, y_train, cv=kfold, scoring='f1', n_jobs=6)\n",
    "    print(np.mean(n_scores['test_score']))\n",
    "    \n",
    "    model = xgb.fit(train_x, y_train)   \n",
    "    pred_y = model.predict(test_dataset)\n",
    "    y_new = le.inverse_transform(pred_y)\n",
    "    generate_dataframe(y_new, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "02174506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb26():\n",
    "    le = LabelEncoder()\n",
    "    y_train = le.fit_transform(train_y)\n",
    "    xgb = XGBClassifier(\n",
    "    tree_method='hist', max_bin=255, n_estimators=400, learning_rate=0.1, objective='binary:logistic', gamma=0.65, reg_alpha=0.9, reg_lambda=0.89, subsample=0.99,\n",
    "    colsample_bytree = 0.99, max_depth=10, colsample_bylevel=0.99\n",
    "    )\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=4)\n",
    "    n_scores = cross_validate(xgb, train_x, y_train, cv=kfold, scoring='f1', n_jobs=6)\n",
    "    print(np.mean(n_scores['test_score']))\n",
    "    \n",
    "    model = xgb.fit(train_x, y_train)   \n",
    "    pred_y = model.predict(test_dataset)\n",
    "    y_new = le.inverse_transform(pred_y)\n",
    "    generate_dataframe(y_new, 26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "74c59750",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb27():\n",
    "    le = LabelEncoder()\n",
    "    y_train = le.fit_transform(train_y)\n",
    "    xgb = XGBClassifier(\n",
    "    tree_method='hist', max_bin=255, n_estimators=400, learning_rate=0.1, objective='binary:logistic', gamma=0.01, reg_alpha=0.001, max_depth=10, subsample=0.99,\n",
    "    colsample_bytree = 0.99, colsample_bylevel=0.99)\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=4)\n",
    "    n_scores = cross_validate(xgb, train_x, y_train, cv=kfold, scoring='f1', n_jobs=6)\n",
    "    print(np.mean(n_scores['test_score']))\n",
    "    \n",
    "    model = xgb.fit(train_x, y_train)   \n",
    "    pred_y = model.predict(test_dataset)\n",
    "    y_new = le.inverse_transform(pred_y)\n",
    "    generate_dataframe(y_new, 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f90e67dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb28():\n",
    "    le = LabelEncoder()\n",
    "    y_train = le.fit_transform(train_y)\n",
    "    xgb = XGBClassifier(\n",
    "    tree_method='hist', max_bin=255, n_estimators=400, learning_rate=0.1, objective='binary:logistic', gamma=0.01, reg_alpha=0.001, max_depth=10)\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=4)\n",
    "    n_scores = cross_validate(xgb, train_x, y_train, cv=kfold, scoring='f1', n_jobs=6)\n",
    "    print(np.mean(n_scores['test_score']))\n",
    "    \n",
    "    model = xgb.fit(train_x, y_train)   \n",
    "    pred_y = model.predict(test_dataset)\n",
    "    y_new = le.inverse_transform(pred_y)\n",
    "    generate_dataframe(y_new, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9149aab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb29():\n",
    "    le = LabelEncoder()\n",
    "    y_train = le.fit_transform(train_y)\n",
    "    xgb = XGBClassifier(\n",
    "    tree_method='hist', max_bin=255, n_estimators=400, learning_rate=0.1, objective='binary:logistic', gamma=0.01, reg_alpha=0.01, max_depth=10, subsample=0.99,\n",
    "    colsample_bytree = 0.99, colsample_bylevel=0.99)\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=4)\n",
    "    n_scores = cross_validate(xgb, train_x, y_train, cv=kfold, scoring='f1', n_jobs=6)\n",
    "    print(np.mean(n_scores['test_score']))\n",
    "    \n",
    "    model = xgb.fit(train_x, y_train)   \n",
    "    pred_y = model.predict(test_dataset)\n",
    "    y_new = le.inverse_transform(pred_y)\n",
    "    generate_dataframe(y_new, 29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1445ebbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost30():\n",
    "    xgb = XGBClassifier(tree_method='hist', learning_rate=0.2, max_depth=10, n_estimators=400, objective='binary:logistic', nthread=4, seed=42)\n",
    "    le = LabelEncoder()\n",
    "    y_train = le.fit_transform(train_y)\n",
    "    \n",
    "    estimator = XGBClassifier(objective='binary:logistic', nthread=4, seed=42)\n",
    "\n",
    "    parameters = {'max_depth': [8, 10], 'n_estimators': [1000, 1200], 'learning_rate': [0.1,0.2]}\n",
    "\n",
    "    grid_search = GridSearchCV(estimator=estimator, param_grid=parameters, scoring='f1', n_jobs=6, cv=5, verbose=True)\n",
    "\n",
    "    grid_search.fit(train_x, y_train)\n",
    "\n",
    "    print(grid_search.best_params_, grid_search.best_score_)\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, random_state=1, shuffle=True)\n",
    "    n_scores = cross_validate(xgb, train_x, y_train, scoring='f1', cv=cv, n_jobs=-1)\n",
    "    print(np.mean(n_scores['test_score']))\n",
    "\n",
    "\n",
    "\n",
    "    model = xgb.fit(train_x, y_train)\n",
    "    pred_y = model.predict(test_dataset)\n",
    "    y_new = le.inverse_transform(pred_y)\n",
    "    generate_dataframe(y_new, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f6268ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost31():\n",
    "    xgb = XGBClassifier(tree_method='hist', learning_rate=0.2, max_depth=10, n_estimators=800, objective='binary:logistic', nthread=4, seed=42)\n",
    "    le = LabelEncoder()\n",
    "    y_train = le.fit_transform(train_y)\n",
    "\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, random_state=1, shuffle=True)\n",
    "    n_scores = cross_validate(xgb, train_x, y_train, scoring='f1', cv=cv, n_jobs=-1)\n",
    "    print(np.mean(n_scores['test_score']))\n",
    "\n",
    "\n",
    "\n",
    "    model = xgb.fit(train_x, y_train)\n",
    "    pred_y = model.predict(test_dataset)\n",
    "    y_new = le.inverse_transform(pred_y)\n",
    "    generate_dataframe(y_new, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36fc7375",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost32():\n",
    "    xgb = XGBClassifier(tree_method='hist', learning_rate=0.2, max_depth=10, n_estimators=1500, objective='binary:logistic', nthread=4, seed=42)\n",
    "    le = LabelEncoder()\n",
    "    y_train = le.fit_transform(train_y)\n",
    "\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, random_state=1, shuffle=True)\n",
    "    n_scores = cross_validate(xgb, train_x, y_train, scoring='f1', cv=cv, n_jobs=-1)\n",
    "    print(np.mean(n_scores['test_score']))\n",
    "\n",
    "\n",
    "\n",
    "    model = xgb.fit(train_x, y_train)\n",
    "    pred_y = model.predict(test_dataset)\n",
    "    y_new = le.inverse_transform(pred_y)\n",
    "    generate_dataframe(y_new, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c47db60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost33():\n",
    "    le = LabelEncoder()\n",
    "    y_train = le.fit_transform(train_y)\n",
    "    xgb = XGBClassifier(\n",
    "    tree_method='hist', max_bin=255, n_estimators=800, learning_rate=0.2, objective='binary:logistic', gamma=0.65, reg_alpha=0.9, reg_lambda=0.89, subsample=0.99,\n",
    "    colsample_bytree = 0.99, max_depth=8, colsample_bylevel=0.99\n",
    "    )\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=4)\n",
    "    n_scores = cross_validate(xgb, train_x, y_train, cv=kfold, scoring='f1', n_jobs=6)\n",
    "    print(np.mean(n_scores['test_score']))\n",
    "    \n",
    "    model = xgb.fit(train_x, y_train)   \n",
    "    pred_y = model.predict(test_dataset)\n",
    "    y_new = le.inverse_transform(pred_y)\n",
    "    generate_dataframe(y_new, 33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "565b8c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb34():\n",
    "    le = LabelEncoder()\n",
    "    y_train = le.fit_transform(train_y)\n",
    "    xgb = XGBClassifier(\n",
    "    tree_method='hist', n_estimators=400, learning_rate=0.1, objective='binary:logistic', gamma=0.01)\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=4)\n",
    "    n_scores = cross_validate(xgb, train_x, y_train, cv=kfold, scoring='f1', n_jobs=6)\n",
    "    print(np.mean(n_scores['test_score']))\n",
    "    \n",
    "    model = xgb.fit(train_x, y_train)   \n",
    "    pred_y = model.predict(test_dataset)\n",
    "    y_new = le.inverse_transform(pred_y)\n",
    "    generate_dataframe(y_new, 34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ea45a7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb35():\n",
    "    le = LabelEncoder()\n",
    "    y_train = le.fit_transform(train_y)\n",
    "    xgb = XGBClassifier(\n",
    "    tree_method='hist', n_estimators=400, learning_rate=0.1, objective='binary:logistic', gamma=0.01, max_depth=10)\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=4)\n",
    "    n_scores = cross_validate(xgb, train_x, y_train, cv=kfold, scoring='f1', n_jobs=6)\n",
    "    print(np.mean(n_scores['test_score']))\n",
    "    \n",
    "    model = xgb.fit(train_x, y_train)   \n",
    "    pred_y = model.predict(test_dataset)\n",
    "    y_new = le.inverse_transform(pred_y)\n",
    "    generate_dataframe(y_new, 35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c1578bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb36():\n",
    "    le = LabelEncoder()\n",
    "    y_train = le.fit_transform(train_y)\n",
    "    xgb = XGBClassifier(\n",
    "    tree_method='hist', n_estimators=400, learning_rate=0.1, objective='binary:logistic', gamma=0.001, max_depth=10)\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=4)\n",
    "    n_scores = cross_validate(xgb, train_x, y_train, cv=kfold, scoring='f1', n_jobs=6)\n",
    "    print(np.mean(n_scores['test_score']))\n",
    "    \n",
    "    model = xgb.fit(train_x, y_train)   \n",
    "    pred_y = model.predict(test_dataset)\n",
    "    y_new = le.inverse_transform(pred_y)\n",
    "    generate_dataframe(y_new, 36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f9eaf56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb37():\n",
    "    le = LabelEncoder()\n",
    "    y_train = le.fit_transform(train_y)\n",
    "    xgb = XGBClassifier(\n",
    "    tree_method='hist', n_estimators=400, learning_rate=0.1, objective='binary:logistic', gamma=0.01, max_depth=8)\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=4)\n",
    "    n_scores = cross_validate(xgb, train_x, y_train, cv=kfold, scoring='f1', n_jobs=6)\n",
    "    print(np.mean(n_scores['test_score']))\n",
    "    \n",
    "    model = xgb.fit(train_x, y_train)   \n",
    "    pred_y = model.predict(test_dataset)\n",
    "    y_new = le.inverse_transform(pred_y)\n",
    "    generate_dataframe(y_new, 37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e4d4c7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost42():\n",
    "    xgb = XGBClassifier(learning_rate=0.1, max_depth=10, n_estimators=1000, objective='binary:logistic', nthread=4, seed=42, tree_method='hist', gamma=0.01)\n",
    "    le = LabelEncoder()\n",
    "    y_train = le.fit_transform(train_y)\n",
    "\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, random_state=1, shuffle=True)\n",
    "    n_scores = cross_validate(xgb, train_x, y_train, scoring='f1', cv=cv, n_jobs=-1)\n",
    "    print(np.mean(n_scores['test_score']))\n",
    "\n",
    "\n",
    "\n",
    "    model = xgb.fit(train_x, y_train)\n",
    "    pred_y = model.predict(test_dataset)\n",
    "    y_new = le.inverse_transform(pred_y)\n",
    "    generate_dataframe(y_new, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "344183f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost43():\n",
    "    xgb = XGBClassifier(learning_rate=0.1, max_depth=10, n_estimators=1000, objective='binary:logistic', nthread=4, seed=42, tree_method='hist', gamma=0.3)\n",
    "    le = LabelEncoder()\n",
    "    y_train = le.fit_transform(train_y)\n",
    "\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, random_state=1, shuffle=True)\n",
    "    n_scores = cross_validate(xgb, train_x, y_train, scoring='f1', cv=cv, n_jobs=-1)\n",
    "    print(np.mean(n_scores['test_score']))\n",
    "\n",
    "\n",
    "\n",
    "    model = xgb.fit(train_x, y_train)\n",
    "    pred_y = model.predict(test_dataset)\n",
    "    y_new = le.inverse_transform(pred_y)\n",
    "    generate_dataframe(y_new, 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8c17e885",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stacking44():\n",
    "    le = LabelEncoder()\n",
    "    y_train = le.fit_transform(train_y) # 0, 1\n",
    "    level_0_clf = dict()\n",
    "    level_0_clf['extra_tree'] = ExtraTreesClassifier(n_estimators=200)\n",
    "    level_0_clf['gradient_boosting'] = GradientBoostingClassifier(learning_rate=0.5)\n",
    "    level_0_clf['xgboost'] = XGBClassifier(tree_method='hist', learning_rate=0.1, max_depth=8, n_estimators=1200, objective='binary:logistic', nthread=4, seed=42)\n",
    "    level_1_clf = XGBClassifier(tree_method='hist', max_bin=255, n_estimators=600, learning_rate=0.1, objective='binary:logistic', gamma=0.65, reg_alpha=0.9, reg_lambda=0.89, subsample=0.99,\n",
    "    colsample_bytree = 0.99, max_depth=10, colsample_bylevel=0.99)\n",
    "\n",
    "    \n",
    "    stacking_model = StackingClassifier(estimators=list(level_0_clf.items()), final_estimator=level_1_clf)\n",
    "                                        \n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=4)\n",
    "    n_scores = cross_validate(stacking_model, train_x, y_train, cv=kfold, scoring='f1', n_jobs=6)\n",
    "    print(np.mean(n_scores['test_score']))\n",
    "    \n",
    "    model = stacking_model.fit(train_x, y_train)\n",
    "    pred_y = model.predict(test_dataset)\n",
    "    y_new = le.inverse_transform(pred_y)\n",
    "    generate_dataframe(y_new, 44)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5e0b2144",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stacking45():\n",
    "    le = LabelEncoder()\n",
    "    y_train = le.fit_transform(train_y) # 0, 1\n",
    "    level_0_clf = dict()\n",
    "    level_0_clf['extra_tree'] = ExtraTreesClassifier(n_estimators=200)\n",
    "    level_0_clf['gradient_boosting'] = GradientBoostingClassifier(learning_rate=0.5)\n",
    "    level_0_clf['xgboost'] = XGBClassifier(tree_method='hist', max_bin=255, n_estimators=600, learning_rate=0.1, objective='binary:logistic', gamma=0.65, reg_alpha=0.9, reg_lambda=0.89, subsample=0.99,\n",
    "    colsample_bytree = 0.99, max_depth=10, colsample_bylevel=0.99)\n",
    "    level_1_clf = XGBClassifier(tree_method='hist', max_bin=255, n_estimators=600, learning_rate=0.1, objective='binary:logistic', gamma=0.65, reg_alpha=0.9, reg_lambda=0.89, subsample=0.99,\n",
    "    colsample_bytree = 0.99, max_depth=10, colsample_bylevel=0.99)\n",
    "\n",
    "    \n",
    "    stacking_model = StackingClassifier(estimators=list(level_0_clf.items()), final_estimator=level_1_clf)\n",
    "                                        \n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=4)\n",
    "    n_scores = cross_validate(stacking_model, train_x, y_train, cv=kfold, scoring='f1', n_jobs=6)\n",
    "    print(np.mean(n_scores['test_score']))\n",
    "    \n",
    "    model = stacking_model.fit(train_x, y_train)\n",
    "    pred_y = model.predict(test_dataset)\n",
    "    y_new = le.inverse_transform(pred_y)\n",
    "    generate_dataframe(y_new, 45)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d3219cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run the above functions\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    print(\"Run the above functions\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
